import torch
import argparse
import numpy as np
from PIL import Image
import Beihang
import os
import onnxruntime as ort
from tqdm import tqdm
import time


def predict_full_image_onnx(image, session, patch_size=224):
    """
    ä½¿ç”¨ ONNX Runtime ä¼šè¯å¯¹æ•´å¼ å›¾åƒè¿›è¡Œåˆ†å—æ¨ç†ï¼ˆæ”¯æŒ FP16 æ¨¡å‹ï¼‰
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        session: ONNX Runtime æ¨ç†ä¼šè¯
        patch_size: åˆ†å—å¤§å°ï¼ˆé»˜è®¤ 224ï¼‰
    Returns:
        pred_mask: åŸå§‹å°ºå¯¸çš„é¢„æµ‹æ©ç ï¼ˆ0-255 uint8ï¼‰
    """
    # 1. è¯»å–å›¾åƒ
    # image = Image.open(image_path).convert('RGB')
    image_np = np.asarray(image).transpose(1, 2, 0)  # (H, W, 3)
    hh, ww, cc = image_np.shape

    # 2. å¡«å……ä¸º patch_size çš„æ•´æ•°å€
    pad_h = (patch_size - hh % patch_size) % patch_size
    pad_w = (patch_size - ww % patch_size) % patch_size
    image_padded = np.pad(image_np, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')
    h_pad, w_pad = image_padded.shape[:2]

    # 3. åˆ›å»ºè¾“å‡º mask
    pred_mask = np.zeros((h_pad, w_pad), dtype=np.float32)

    # 4. å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º float16ï¼ˆå…³é”®ï¼šåŒ¹é… FP16 æ¨¡å‹è¾“å…¥ï¼‰
    image_float = image_padded.astype(np.float32) / 255.0
    # âœ… å¦‚æœæ¨¡å‹æ˜¯ FP16ï¼Œå»ºè®®è¾“å…¥ä¹Ÿç”¨ float16
    image_float16 = image_float.astype(np.float16)  # (H, W, 3)
    image_float16 = np.transpose(image_float16, (2, 0, 1))  # (3, H, W)

    # 5. è·å–è¾“å…¥/è¾“å‡ºåç§°
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    # 6. åˆ†å—æ¨ç†
    for i in range(0, h_pad, patch_size):
        for j in range(0, w_pad, patch_size):
            patch = image_float16[:, i:i + patch_size, j:j + patch_size]  # (3, 224, 224)
            patch = np.expand_dims(patch, axis=0)  # (1, 3, 224, 224)

            # ONNX æ¨ç†ï¼ˆè¾“å…¥ä¸º float16ï¼‰
            pred = session.run([output_name], {input_name: patch})[0]  # (1, 1, 224, 224)

            # äºŒå€¼åŒ–ï¼ˆè¾“å‡ºå¯èƒ½æ˜¯ float32 æˆ– float16ï¼Œç»Ÿä¸€è½¬ä¸º float32 å¤„ç†ï¼‰
            pred_binary = (pred > 0.5).astype(np.float32)
            pred_patch = pred_binary[0, 0]  # (224, 224)
            pred_mask[i:i + patch_size, j:j + patch_size] = pred_patch

    # 7. å»é™¤å¡«å……ï¼Œæ¢å¤åŸå§‹å°ºå¯¸
    pred_mask = pred_mask[:hh, :ww]

    # 8. è½¬ä¸º 0-255 çš„ uint8 å›¾åƒ
    pred_mask = (pred_mask * 255).astype(np.uint8)

    return pred_mask


def pre_process(image_path, save_dir):
    seed = 1616
    process_num = 1
    cam = "01"
    untar_dir = "/data/yxq/workspace/data/untar/"
    prestored_data = "/data/yxq/workspace/data/models20250108/config/l04/prestored_data/"
    imgs = Beihang.preprocess(image_path, untar_dir=untar_dir, prestored_data=prestored_data, save_dir=save_dir, cam=cam, seed=seed, process_num=process_num)
    return imgs


def main(args):
    if not os.path.exists(args.onnx_model):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {args.onnx_model}")

    L1_imgs = pre_process(args.image_path, args.output_path)
    # print("L1_imgs", L1_imgs[0].shape)

    # è®¾ç½® providersï¼ˆä¼˜å…ˆä½¿ç”¨ CUDAï¼‰
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
    try:
        # print("Available providers at import time:", ort.get_available_providers())
        # import pdb
        # pdb.set_trace()
        session = ort.InferenceSession(args.onnx_model, providers=providers)
        active_provider = session.get_providers()[0]
        print(f"âœ… æˆåŠŸåŠ è½½ ONNX æ¨¡å‹ï¼Œä½¿ç”¨è®¾å¤‡: {active_provider}")

    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        exit(1)

    os.makedirs(args.output_path, exist_ok=True)

    for i, img in enumerate(L1_imgs):
        start_time = time.time()
        prediction = predict_full_image_onnx(img, session, patch_size=224)
        end_time = time.time()
        print(f"âœ… ç¬¬{i + 1}/{len(L1_imgs)}å¼ å›¾ç‰‡æ¨ç†å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")

        base_name = f"result_{i + 1}.tif"
        out_path = os.path.join(args.output_path, base_name)

        result = Image.fromarray(prediction)
        result.save(out_path)
    print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {args.output_path}")


if __name__ == "__main__":
    # image_path = "./data/XSD-test/converted.tif"
    # output_path = "./data/XSD-test/predicted-resunet.tif"

    parser = argparse.ArgumentParser(description="ResUnet full image prediction")
    parser.add_argument('--image_path', type=str, default="/data/yxq/workspace/data/L0/", help='Path to input image')
    parser.add_argument('--output_path', type=str, default="/data/yxq/workspace/data/output/python/Beihang/", help='Path to output image')
    # parser.add_argument('--pre_process_path', type=str, default='/output/python/Beihang/')
    parser.add_argument('--onnx_model', type=str, default='/data/yxq/workspace/code/Code_Library/Beihang/test/test/checkpoints/quantized_gpu/resunet_fp16.onnx',
                        help='Path to model checkpoint')
    args = parser.parse_args()
    main(args)